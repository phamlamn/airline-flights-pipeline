{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "028c51c2-b172-41a7-99b1-0234e3932931",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/04 19:38:01 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType\n",
    "from pyspark.sql.functions import lit, isnull, when, count, col, regexp_extract, concat_ws, to_date, expr, quarter, when, date_add, year, month, day, dayofweek, broadcast, avg, min, max, like\n",
    "\n",
    "# Define spark session config\n",
    "spark_configs = {\n",
    "    'spark.master': 'spark://spark-iceberg:7077',\n",
    "    'spark.sql.catalog.prod': 'org.apache.iceberg.spark.SparkCatalog',\n",
    "    'spark.sql.catalog.prod.io-impl': 'org.apache.iceberg.aws.s3.S3FileIO',\n",
    "    'spark.sql.catalog.prod.s3.endpoint': 'http://minio:9000',\n",
    "    'spark.sql.catalog.prod.type': 'rest',\n",
    "    'spark.sql.catalog.prod.uri': 'http://rest:8181',\n",
    "    'spark.sql.catalog.prod.warehouse': 's3://warehouse',\n",
    "    'spark.sql.defaultCatalog': 'prod',\n",
    "    'spark.driver.memory': '1G',\n",
    "    'spark.executor.memory': '1G'\n",
    "}\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName('Agg Fact Testing')\n",
    "    .config(map=spark_configs)\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aca6426e-7032-48c8-a7e7-79920ccb5d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dim_dates_df(spark: SparkSession) -> DataFrame:\n",
    "    # Initialize dates_df\n",
    "    dates_df = spark.range(365) \\\n",
    "        .withColumn('date', expr('date_add(\"2015-01-01\", CAST(id AS INT))')) \\\n",
    "        .withColumn('year', year('date')) \\\n",
    "        .withColumn('month', month('date')) \\\n",
    "        .withColumn('day', day('date')) \\\n",
    "        .withColumn('day_of_week', dayofweek('date')) \\\n",
    "        .withColumn('quarter', quarter('date')) \\\n",
    "        .drop('id')\n",
    "\n",
    "    # List of U.S. federal holidays\n",
    "    us_holidays_2015 = [\n",
    "        (\"2015-01-01\", \"New Year's Day\"),\n",
    "        (\"2015-01-19\", \"Martin Luther King Jr. Day\"),\n",
    "        (\"2015-02-16\", \"Presidents' Day\"),\n",
    "        (\"2015-05-25\", \"Memorial Day\"),\n",
    "        (\"2015-07-04\", \"Independence Day\"),\n",
    "        (\"2015-09-07\", \"Labor Day\"),\n",
    "        (\"2015-10-12\", \"Columbus Day\"),\n",
    "        (\"2015-11-11\", \"Veterans Day\"),\n",
    "        (\"2015-11-26\", \"Thanksgiving Day\"),\n",
    "        (\"2015-12-25\", \"Christmas Day\"),\n",
    "    ]\n",
    "    \n",
    "    # Create holidays_df and cast date from STRING to DATE type\n",
    "    holidays_df = spark.createDataFrame(us_holidays_2015, ['holiday_date', 'holiday_name'])\n",
    "    holidays_df = holidays_df.withColumn('holiday_date', to_date('holiday_date'))\n",
    "\n",
    "    # Join holidays to date_df and add is_holiday column\n",
    "    dates_df = dates_df \\\n",
    "        .join(\n",
    "            broadcast(holidays_df),\n",
    "            dates_df.date == holidays_df.holiday_date,\n",
    "            'left'\n",
    "        ) \\\n",
    "        .withColumn(\n",
    "            'is_holiday',\n",
    "            when(col('holiday_name').isNotNull(), lit(True)).otherwise(lit(False))\n",
    "        ) \\\n",
    "        .drop('holiday_date') \\\n",
    "        .sort('date')\n",
    "\n",
    "    # Rearrange date to be first column,\n",
    "    dates_df = dates_df.select('date', *[col(c) for c in dates_df.columns if c != 'date'])\n",
    "    return dates_df\n",
    "\n",
    "dates_df = generate_dim_dates_df(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9ca6656-23b8-4103-b653-9cfe8e9af88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+----------+----+-----+---+-----------+-------+------------+----------+\n",
      "|      date|airline|flight_number|tail_number|origin_airport|destination_airport|scheduled_departure|departure_time|departure_delay|taxi_out|wheels_off|scheduled_time|elapsed_time|air_time|distance|wheels_on|taxi_in|scheduled_arrival|arrival_time|arrival_delay|diverted|cancelled|cancellation_reason|air_system_delay|security_delay|airline_delay|late_aircraft_delay|weather_delay|is_delayed|year|month|day|day_of_week|quarter|holiday_name|is_holiday|\n",
      "+----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+----------+----+-----+---+-----------+-------+------------+----------+\n",
      "|2015-06-01|     AA|            1|     N798AA|           JFK|                LAX|                900|           858|             -2|      66|      1004|           376|         392|     315|    2475|     1219|     11|             1216|        1230|           14|       0|        0|               NULL|            NULL|          NULL|         NULL|               NULL|         NULL|         0|2015|    6|  1|          2|      2|        NULL|     false|\n",
      "|2015-06-01|     AA|            2|     N784AA|           LAX|                JFK|                900|           957|             57|      28|      1025|           342|         329|     294|    2475|     1819|      7|             1742|        1826|           44|       0|        0|               NULL|               2|             0|            0|                 42|            0|         1|2015|    6|  1|          2|      2|        NULL|     false|\n",
      "|2015-06-01|     AA|            3|     N795AA|           JFK|                LAX|               1245|          1533|            168|      24|      1557|           365|         357|     324|    2475|     1821|      9|             1550|        1830|          160|       0|        0|               NULL|               0|             0|            9|                151|            0|         1|2015|    6|  1|          2|      2|        NULL|     false|\n",
      "|2015-06-01|     AA|            4|     N792AA|           LAX|                JFK|               1220|          1323|             63|      21|      1344|           340|         327|     297|    2475|     2141|      9|             2100|        2150|           50|       0|        0|               NULL|              50|             0|            0|                  0|            0|         1|2015|    6|  1|          2|      2|        NULL|     false|\n",
      "|2015-06-01|     AA|            5|     N360AA|           DFW|                HNL|               1350|          1352|              2|      17|      1409|           512|         501|     481|    3784|     1710|      3|             1722|        1713|           -9|       0|        0|               NULL|            NULL|          NULL|         NULL|               NULL|         NULL|         1|2015|    6|  1|          2|      2|        NULL|     false|\n",
      "|2015-06-01|     AA|            6|     N357AA|           OGG|                DFW|               1715|          1711|             -4|      16|      1727|           436|         413|     391|    3711|      458|      6|              531|         504|          -27|       0|        0|               NULL|            NULL|          NULL|         NULL|               NULL|         NULL|         0|2015|    6|  1|          2|      2|        NULL|     false|\n",
      "|2015-06-01|     AA|            7|     N357AA|           DFW|                OGG|                905|          1041|             96|      25|      1106|           502|         493|     463|    3711|     1349|      5|             1227|        1354|           87|       0|        0|               NULL|               0|             0|           87|                  0|            0|         1|2015|    6|  1|          2|      2|        NULL|     false|\n",
      "|2015-06-01|     AA|            8|     N362AA|           HNL|                DFW|               1740|          1738|             -2|      20|      1758|           459|         420|     397|    3784|      535|      3|              619|         538|          -41|       0|        0|               NULL|            NULL|          NULL|         NULL|               NULL|         NULL|         0|2015|    6|  1|          2|      2|        NULL|     false|\n",
      "|2015-06-01|     AA|            9|     N797AA|           JFK|                LAX|                700|           654|             -6|      39|       733|           371|         377|     325|    2475|      958|     13|             1011|        1011|            0|       0|        0|               NULL|            NULL|          NULL|         NULL|               NULL|         NULL|         0|2015|    6|  1|          2|      2|        NULL|     false|\n",
      "|2015-06-01|     AA|           10|     N790AA|           LAX|                JFK|               2155|          2210|             15|      30|      2240|           328|         339|     299|    2475|      639|     10|              623|         649|           26|       0|        0|               NULL|              11|             0|           15|                  0|            0|         1|2015|    6|  1|          2|      2|        NULL|     false|\n",
      "+----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+----------+----+-----+---+-----------+-------+------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read flights table\n",
    "flights_df = spark.table('prod.db.fact_flights')\n",
    "\n",
    "# Join dim_date table to flights\n",
    "flights_df = flights_df \\\n",
    "    .join(\n",
    "        broadcast(dates_df),\n",
    "        ['date']\n",
    "    )\n",
    "\n",
    "flights_df.createOrReplaceTempView('flights')\n",
    "\n",
    "flights_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "728a2e73-95b6-4085-b345-d95fb10d6323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_delay_metrics_rollup(\n",
    "    input_df: DataFrame,\n",
    "    non_time_columns: list[str],\n",
    "    time_columns: list[str]\n",
    ") -> DataFrame:\n",
    "\n",
    "    # Concatenate both list of columns\n",
    "    cube_columns = non_time_columns + time_columns\n",
    "\n",
    "    # Calculate the aggregate values for the cube\n",
    "    output_df = input_df \\\n",
    "        .rollup(*cube_columns) \\\n",
    "        .agg(\n",
    "            count('*').alias('total_flights'),\n",
    "            count(when(col('is_delayed') == True, 1)).alias('delayed_flights'),\n",
    "            ( count(when(col('is_delayed') == True, 1)) / count('*') ).alias('delay_rate'),\n",
    "            avg('departure_delay').alias('avg_delay_time')\n",
    "        )\n",
    "\n",
    "    # Calculate aggregation label to add as column\n",
    "    time_agg_level = get_aggregation_level(time_columns)\n",
    "    agg_level = get_aggregation_level(non_time_columns)\n",
    "\n",
    "    # Add (time_)agg_level columns\n",
    "    output_df = output_df \\\n",
    "        .withColumn('time_agg_level', time_agg_level) \\\n",
    "        .withColumn('agg_level', agg_level)\n",
    "    \n",
    "    return output_df\n",
    "\n",
    "def get_aggregation_level(columns: list[str]):\n",
    "    # TODO add comments\n",
    "    # Returns col\n",
    "    agg_level = concat_ws(\n",
    "        '_',\n",
    "        *[when(col(c).isNotNull(), lit(c)) for c in columns]\n",
    "    )\n",
    "\n",
    "    all_nulls = lit(True)\n",
    "    for c in columns:\n",
    "        all_nulls &= col(c).isNull()\n",
    "    agg_level = when(all_nulls, 'all').otherwise(agg_level)\n",
    "    return agg_level\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10d04db2-5045-4477-92f4-18b64412db00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17742"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = flights_df.sample(0.1)\n",
    "\n",
    "# Confirm redundant aggs for cube with cancelled and cancellation_reason\n",
    "time_columns = ['year', 'month']\n",
    "non_time_columns = ['airline', 'origin_airport']\n",
    "# non_time_columns = ['airline', 'origin_airport', 'cancelled', 'cancellation_reason']\n",
    "\n",
    "\n",
    "# agg_df = agg_delay_metrics_cube_by_cols(temp_df, time_columns, non_time_columns)\n",
    "agg_df = agg_delay_metrics_rollup(temp_df, non_time_columns, time_columns)\n",
    "\n",
    "# agg_df.filter(col('agg_level') == 'cancelled_cancellation_reason')).show(100)\n",
    "# agg_df \\\n",
    "#     .filter(\n",
    "#         (col('year').isNull()) &\n",
    "#         (col('month').isNull()) &\n",
    "#         (col('airline').isNull()) &\n",
    "#         (col('origin_airport').isNull()) &\n",
    "#         (col('cancellation_reason') == lit('A'))\n",
    "#     ) \\\n",
    "#     .show()\n",
    "agg_df.count()\n",
    "# agg_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcd5ec8-b027-4d10-ba57-9478b400a052",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouping_set_sql = \"\"\"\n",
    "SELECT\n",
    "    airline,\n",
    "    year,\n",
    "    month,\n",
    "    day_of_week,\n",
    "    COUNT(*) AS total_flights,\n",
    "    COUNT(CASE WHEN is_delayed = 1 THEN 1 END) AS delayed_flights,\n",
    "    delayed_flights / total_flights AS delay_rate,\n",
    "    AVG(departure_delay) AS avg_delay_time\n",
    "FROM flights\n",
    "GROUP BY\n",
    "    GROUPING SETS (\n",
    "        \n",
    "            --airline,\n",
    "            --day_of_week,\n",
    "            --ROLLUP(year, month),\n",
    "            --GROUPING SETS(airline, ROLLUP(year, month))\n",
    "            CUBE(airline, (year, month), day_of_week)\n",
    "        \n",
    "    )\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "temp_df = spark.sql(grouping_set_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83c93e27-0182-4028-9acc-ec70b6493e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((cancelled), (cancelled, year), (cancelled, month), (cancelled, year, month))\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def build_grouping_sets(grouping_columns):\n",
    "    grouping_sets = []\n",
    "    for i in range(len(grouping_columns) + 1):\n",
    "        for subset in itertools.combinations(grouping_columns, i):\n",
    "            if \"cancelled\" in subset:\n",
    "                grouping_sets.append(subset)\n",
    "    grouping_sets_str = str(tuple(grouping_sets)).replace(\"'\", \"\").replace(\",)\", \")\")\n",
    "    return grouping_sets_str\n",
    "\n",
    "grouping_cols = [\n",
    "    'cancelled',\n",
    "    'year',\n",
    "    'month'\n",
    "]\n",
    "grouping_sets = build_grouping_sets(grouping_cols)\n",
    "print(grouping_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf5df98-2d5a-4001-83c8-9f80121c0346",
   "metadata": {},
   "outputs": [],
   "source": [
    "(month) (day_of_week) (month, airport) (airline) (airline, month) (airline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132b9a92-42d8-4b5d-af4f-c35e361336ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouping_sets = (\n",
    "    (year), (year, month),\n",
    "    \n",
    "    (airline), (airline, year), (airline, year, month),\n",
    "    (origin_airport), (origin_airport, year), (origin_airport, year, month)\n",
    "    \n",
    "    ((cancelled), (cancelled, year), (cancelled, year, month))\n",
    "    ((cancellation_reason), (cancellation_reason, year), (cancellation_reason, year, month))\n",
    "\n",
    "    (day_of_week), \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7b5a6d38-bbff-4b25-a870-9719ee2882be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 129:=============================================>         (10 + 2) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-------+------+-----------+---------+\n",
      "|year|month|airline| count|grouping_id|agg_level|\n",
      "+----+-----+-------+------+-----------+---------+\n",
      "|2015| NULL|   NULL|582343|          3|     year|\n",
      "+----+-----+-------+------+-----------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "temp_df.createOrReplaceTempView('flights')\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    year,\n",
    "    month,\n",
    "    airline,\n",
    "    COUNT(*) AS count,\n",
    "    GROUPING_ID(year, month, airline) AS grouping_id\n",
    "FROM flights\n",
    "GROUP BY GROUPING SETS (\n",
    "    (year),\n",
    "    (year, month),\n",
    "    \n",
    "    (airline), \n",
    "    (airline, year), \n",
    "    (airline, year, month)\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "cols = ['year', 'month', 'airline']\n",
    "\n",
    "agg_df = spark.sql(query)\n",
    "agg_level = get_aggregation_level(cols)\n",
    "agg_df = agg_df.withColumn('agg_level', agg_level)\n",
    "\n",
    "# agg_df.show()\n",
    "agg_df.filter('grouping_id = \"3\"').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2f3699-695e-47c6-b3bc-fcb4e5967cc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84002b5e-8173-4432-8465-d514924c71d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
